{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_exploration.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D8nETDBoRMLX"
      ],
      "authorship_tag": "ABX9TyO2vMjHspgNns/16GRux62z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeleneFabia/nlp-exploration/blob/main/nlp_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face NLP Course\n",
        "\n"
      ],
      "metadata": {
        "id": "ggj-itvURGAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "EL72HWG4Rfk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Datasets)"
      ],
      "metadata": {
        "id": "D8nETDBoRMLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports \n",
        "from datasets import (\n",
        "    load_dataset_builder, \n",
        "    load_dataset,\n",
        ")\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    AutoTokenizer\n",
        ")\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import(\n",
        "    DataLoader\n",
        ")"
      ],
      "metadata": {
        "id": "6lVynTbIRDi5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_builder = load_dataset_builder(path=\"poem_sentiment\")\n",
        "\n",
        "train_dataset = load_dataset(path=\"poem_sentiment\", split=\"train\")\n",
        "# valid_dataset = load_dataset(path=\"poem_sentiment\", split=\"validation\")\n",
        "# test_dataset = load_dataset(path=\"poem_sentiment\", split=\"test\")"
      ],
      "metadata": {
        "id": "q1_6R2RdRabm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Description:\", train_dataset.description)\n",
        "print(\"Num data entries:\", len(train_dataset))\n",
        "print(\"Column names:\", train_dataset.column_names)\n",
        "print(\"Classes:\", train_dataset.features[\"label\"].names)\n",
        "print(\"Example data entry:\", train_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYEbNPw0ThoP",
        "outputId": "ceb3e084-91ef-488b-e0c6-3e13b6670f76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description: Poem Sentiment is a sentiment dataset of poem verses from Project Gutenberg. This dataset can be used for tasks such as sentiment classification or style transfer for poems.\n",
            "\n",
            "Num data entries: 892\n",
            "Column names: ['id', 'verse_text', 'label']\n",
            "Classes: ['negative', 'positive', 'no_impact', 'mixed']\n",
            "Example data entry: {'id': 0, 'verse_text': 'with pale blue berries. in these peaceful shades--', 'label': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "bKBHTgjCUS6X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_enc_ds = train_dataset.map(lambda examples: \n",
        "                                          tokenizer(\n",
        "                                              examples[\"verse_text\"], \n",
        "                                              truncation=True,\n",
        "                                              padding=\"max_length\",\n",
        "                                          ),\n",
        "                                 batched=True\n",
        "                                 )"
      ],
      "metadata": {
        "id": "C_szpKZAVZws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column names of encoded dataset:\", train_enc_ds.column_names)\n",
        "print(\"Tokenized data entry:\", train_enc_ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfoaHcQJXmUi",
        "outputId": "53f4e7a5-bfd8-4111-aa3d-2e58e135195b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names of encoded dataset: ['attention_mask', 'id', 'input_ids', 'label', 'token_type_ids', 'verse_text']\n",
            "Tokenized data entry: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'id': 0, 'input_ids': [101, 1114, 4554, 2221, 26571, 119, 1107, 1292, 9441, 16327, 118, 118, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'verse_text': 'with pale blue berries. in these peaceful shades--'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- What are attention mask, input ids and token type ids?"
      ],
      "metadata": {
        "id": "tHiYSk3vYXpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use dataset with pytorch\n",
        "train_enc_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# create pytorch data loader\n",
        "train_dl = DataLoader(train_enc_ds, batch_size=32)\n",
        "next(iter(train_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2qNF-9iZmYy",
        "outputId": "aa26e791-b87f-42d0-8cfb-2b77679b5f0b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'input_ids': tensor([[  101,  1114,  4554,  ...,     0,     0,     0],\n",
              "         [  101,  1122,  5611,  ...,     0,     0,     0],\n",
              "         [  101,  1105,  1115,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  1106,  1115,  ...,     0,     0,     0],\n",
              "         [  101,   192,  2386,  ...,     0,     0,     0],\n",
              "         [  101,  1123, 15219,  ...,     0,     0,     0]]),\n",
              " 'label': tensor([1, 2, 0, 3, 3, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Transformer models"
      ],
      "metadata": {
        "id": "XW9BaK3rdrwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What can Transformers do?\n",
        "\n",
        "Playing around with HuggingFace's OTB models:"
      ],
      "metadata": {
        "id": "la2dcEgcgzkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "CXs80bVxaRsj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"The ocean is beautiful.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Haf-S0XMe5WW",
        "outputId": "3d0b8aa7-0f4a-4c47-9ba0-0863e8b5a906"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998816251754761}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"Looking at the ocean in front of me, I felt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zyK7aVcfOzF",
        "outputId": "bb988a42-89e6-4395-eb3f-3f382f96b69b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Looking at the ocean in front of me, I felt like an airplane flying right.\\n\\nThe storm had descended very quickly, so it appeared this was about to fall at a later date.\\n\\nWe all started feeling a wave of panic:'}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"What is my hobby?\",\n",
        "    context=\"I work as an engineer, but in my free time I enjoy cooking.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17-acrlJfVII",
        "outputId": "d113b7d4-42f2-4bde-a58e-777fd8e4ca06"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'cooking', 'end': 58, 'score': 0.428894579410553, 'start': 51}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do Transformers work?"
      ],
      "metadata": {
        "id": "1olfiIiGg1tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important concepts: \n",
        "- **self-supervised learning**: labels are automatically computed from the input\n",
        "- **pretraining**: training a model from scratch on very large amounts of data\n",
        "- **transfer learning**: fine-tuning a pretrained model in a supervised manner with a smaller dataset for a specific language task\n",
        "- **encoder**: receives input and builds representation of it (optimized for  acquiring an understanding from inputs)\n",
        "- **decoder**: receives encoder's representation plus other inputs in order to generate a target sequence (optimized for generating an output)\n",
        "- **encoder-only models** (e.g., BERT, DistilBERT): for tasks that require understanding of the input e.g., sentence classification, named entity recognition\n",
        "- **decoder-only models** (e.g., GPT, GPT-2): for generative tasks e.g., text generation\n",
        "- **encoder-decoder /seq2seq models** (e.g., BART, Marian): for generative tasks that require an input e.g., translation, summarization\n",
        "- **attention layer**: tells the model to pay attention to specific words in the input\n"
      ],
      "metadata": {
        "id": "qXjSScTphGWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Using HuggingFace Transformers"
      ],
      "metadata": {
        "id": "7ew07kVshL9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple pipeline"
      ],
      "metadata": {
        "id": "Bnn_FifDsSyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer:\n",
        "- splits the input words/subwords/symbols (=tokens), since a model cannot process words directly\n",
        "- maps each token to an integer\n",
        "- adds additional inputs necessary for the model\n",
        "- tokenization needs to happen in exactly the same way as was done with the data used for pretraining a model"
      ],
      "metadata": {
        "id": "vPJDLVTxmcly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "\n",
        "from torch.nn.functional import softmax"
      ],
      "metadata": {
        "id": "4gr-W47rgqZ2"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "Kd3t9LNtnYh9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = [\"I am looking at the ocean. How beautiful!\"]\n",
        "tokenized_input = tokenizer(input, padding=True, truncation=True)\n",
        "print(tokenized_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSJiXRmynjKI",
        "outputId": "24b1c0f8-7ec4-443e-b8e7-f7473fcfb25e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 1045, 2572, 2559, 2012, 1996, 4153, 1012, 2129, 3376, 999, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input[\"input_ids\"] = torch.tensor(tokenized_input[\"input_ids\"])\n",
        "tokenized_input[\"attention_mask\"] = torch.tensor(tokenized_input[\"attention_mask\"])\n",
        "print(tokenized_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUXDuJPAotdr",
        "outputId": "20078822-2f04-4235-82e1-049d1b7fd52c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1045, 2572, 2559, 2012, 1996, 4153, 1012, 2129, 3376,  999,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "input vector:\n",
        "- of shape (batch_size, sequence_length, hidden_size)\n",
        "- batch_size: number of sequences per batch\n",
        "- sequence_length: length of numerical representation of sequence\n",
        "- hidden_size:  vector dimension of each model input (depends on the model)"
      ],
      "metadata": {
        "id": "V8p8kRf1oWSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "U5hIS-vdn0Dx"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(**tokenized_input)\n",
        "print(output.logits)\n",
        "prediction = softmax(output.logits, dim=1)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_XgEvwep2zt",
        "outputId": "02600a3e-56b7-4704-be9a-d4d794ce1492"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.3032,  4.5966]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1.3640e-04, 9.9986e-01]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_id = 0\n",
        "class_prediction = int(torch.argmax(prediction))\n",
        "print(f\"Prediction for sentiment of '{input[input_id]}':\", \n",
        "      model.config.id2label[class_prediction],\n",
        "      f\"with {prediction.tolist()[input_id][class_prediction]:.4f}% probability\"\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVqVEHzBqaZA",
        "outputId": "5f27c33b-5eb3-40c8-a52a-f2534e083c14"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for sentiment of 'I am looking at the ocean. How beautiful!': POSITIVE with 0.9999% probability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "X3cO9btcsWl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import (\n",
        "    BertConfig,\n",
        "    BertModel,\n",
        ")"
      ],
      "metadata": {
        "id": "G9x-xh0VsX5y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig()\n",
        "print(config)\n",
        "model = BertModel(config)  # randomly initialized\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")  # pretrained (https://huggingface.co/bert-base-cased)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUIZfUHMsy_H",
        "outputId": "b332b4db-683d-4dc6-dc92-e97361bc8d9f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.15.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/path/to/my_trained_model\")"
      ],
      "metadata": {
        "id": "f3sT4dr4s25i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizers"
      ],
      "metadata": {
        "id": "OV0-urZ1-R3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used to transform language data into numerical data so that te model can process it. Some approach are:\n",
        "\n",
        "**Word-based tokenizer**\n",
        "- split raw text into words and find numerical representation for them\n",
        "- would need A LOT of different input IDs (one for each word in a language) \n",
        "- no means of showing relationships between words (\"dog\" and \"dogs\" would have different input IDs)\n",
        "- need \"unknown\" token (\"[UNK]\") for words that are not in the vocabulary.\n",
        "\n",
        "**Character-based tokenizer**\n",
        "- raw text is split into characters\n",
        "- fewer distinct input IDs are necessary but numerical sequences would be much longer with this approach\n",
        "\n",
        "**Subword tokenizer**\n",
        "- frequently used words remain as they are, less frequently used ones are split into meaningful subwords (e.g., \"annoyingly\" --> \"annoying\" + \"ly\")\n",
        "- good tradeoff between small number of distinct input IDs and short sequences"
      ],
      "metadata": {
        "id": "XK1v2Nv_-a3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    AutoTokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "H2PhghDD-EOE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "# essentially the same, but the second module is a wrapper that can be used with any checkpoint"
      ],
      "metadata": {
        "id": "Rdnmd-6e-Ebk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"The sea is incredibly blue and glittering today.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz1CZNn4-EfE",
        "outputId": "2a49f593-1ece-4e39-e7ea-f6290db9363c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1109, 2343, 1110, 12170, 2221, 1105, 22837, 2052, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**encoding** = general process of converting text to numbers\n",
        "\n",
        "tokenization = splitting text into tokens (according to the way it was done for the pretrained model we want to use)"
      ],
      "metadata": {
        "id": "34r1EEXWAw2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(\"The sea is incredibly blue and glittering today.\")\n",
        "print(tokens)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZBnVsCw-Eic",
        "outputId": "c287046c-e518-4749-94fe-a6d525ec1cd0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'sea', 'is', 'incredibly', 'blue', 'and', 'glittering', 'today', '.']\n",
            "[1109, 2343, 1110, 12170, 2221, 1105, 22837, 2052, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**decoding** = converting numbers to text"
      ],
      "metadata": {
        "id": "CEJaOF7OB4wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.decode(ids)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN6udvxN-Elx",
        "outputId": "3238ce0a-23cc-4e83-b371-f0362d8167a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sea is incredibly blue and glittering today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling multiple sequences"
      ],
      "metadata": {
        "id": "8Roxdcb8CKUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BlnPpCuDCCDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}