{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_with_huggingface.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D8nETDBoRMLX",
        "XW9BaK3rdrwL",
        "7ew07kVshL9k"
      ],
      "authorship_tag": "ABX9TyMhtq+wCxe6ffV0tXxBcWse",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2366d78eee34564b5ddb81ef1e3f9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_944c636a4ed74bd594ee590b9f4d9767",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aadee3faa2324a398330421f3c791d6b",
              "IPY_MODEL_772c71e15ed843a3a2c128f4a6a4f993",
              "IPY_MODEL_f2472e3fb5d748849bba736d1e878cbc"
            ]
          }
        },
        "944c636a4ed74bd594ee590b9f4d9767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aadee3faa2324a398330421f3c791d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdf4970dd87247b1a38f4f14b2bef2cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76f756b9d3ea4afbb40ce402ea0aa2f5"
          }
        },
        "772c71e15ed843a3a2c128f4a6a4f993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a458e0e8a5a4f259e51ad62697f02ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1815442e0ea54d3f82ff5dca53d76ac1"
          }
        },
        "f2472e3fb5d748849bba736d1e878cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c65dc5ac07f74ec68e1aa64a3d067764",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 57.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59f30938374944f1a5f2a258c59d9412"
          }
        },
        "bdf4970dd87247b1a38f4f14b2bef2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76f756b9d3ea4afbb40ce402ea0aa2f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a458e0e8a5a4f259e51ad62697f02ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1815442e0ea54d3f82ff5dca53d76ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c65dc5ac07f74ec68e1aa64a3d067764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59f30938374944f1a5f2a258c59d9412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86638f4637694954ba4c47ea7fa657c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e6b1274a82045f29b3b03488dc5a250",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_67d05f6270734c13b91af073076faf47",
              "IPY_MODEL_28b47bb248c94c2384fa4fbded5882ec",
              "IPY_MODEL_6d205bf89cbc4f3fa6afdfe4dcd006c6"
            ]
          }
        },
        "2e6b1274a82045f29b3b03488dc5a250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67d05f6270734c13b91af073076faf47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00b754ceec9a409198adc96e5df4b201",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c80ac0e8f1384342a0e9fa6000a1ca16"
          }
        },
        "28b47bb248c94c2384fa4fbded5882ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e43e199ba94f415ca2f774590c405c20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_914ce147edbe4c308b0ffa2dd35ed851"
          }
        },
        "6d205bf89cbc4f3fa6afdfe4dcd006c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cff1bb1518e544ed932264857c4f6903",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  6.09ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_667144992b8d45b8918a6ae220725561"
          }
        },
        "00b754ceec9a409198adc96e5df4b201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c80ac0e8f1384342a0e9fa6000a1ca16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e43e199ba94f415ca2f774590c405c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "914ce147edbe4c308b0ffa2dd35ed851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cff1bb1518e544ed932264857c4f6903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "667144992b8d45b8918a6ae220725561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8a96cb943de4cf39f2b6a9876e55141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_253f3722292247488e5eacc1efe8ad46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b08ef877b51f420492d7b3569e72d31b",
              "IPY_MODEL_049c2becd460423583087dfaebbd4e9d",
              "IPY_MODEL_4bb229c9625348f6b98b140b84efa1e0"
            ]
          }
        },
        "253f3722292247488e5eacc1efe8ad46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b08ef877b51f420492d7b3569e72d31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f86476e1c4a74f17a7cc80d86668a647",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cd763587be54a868c1947730d82ee32"
          }
        },
        "049c2becd460423583087dfaebbd4e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d155ba5846b74184ad81cf7a591203dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e56cb107bf34af1a60393f4dbd81257"
          }
        },
        "4bb229c9625348f6b98b140b84efa1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22829a9cd4f84f34b87281df5c66bb2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  7.07ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd96b11555b84777a397675495f90871"
          }
        },
        "f86476e1c4a74f17a7cc80d86668a647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cd763587be54a868c1947730d82ee32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d155ba5846b74184ad81cf7a591203dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e56cb107bf34af1a60393f4dbd81257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22829a9cd4f84f34b87281df5c66bb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd96b11555b84777a397675495f90871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d329ec16e174052ae7b2ae195055c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9eb064e07a14575913afea9774cf43b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6bb7aac74ea482dbd6de7a019f63a0a",
              "IPY_MODEL_ba696fc8349644b8ba72a4dd28ef531b",
              "IPY_MODEL_b88a56c26db54ba6beebaf7017478b02"
            ]
          }
        },
        "b9eb064e07a14575913afea9774cf43b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6bb7aac74ea482dbd6de7a019f63a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0036c351554c4006961c8b44805a6158",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b5ed87c79a24c0d8d4b31ad708d6a82"
          }
        },
        "ba696fc8349644b8ba72a4dd28ef531b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f7af2510b8a4987af9519d11f0b582e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa745fa819d04d199f75ad7578d80aea"
          }
        },
        "b88a56c26db54ba6beebaf7017478b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7449205bb3b24f2bb7c5b49d35478461",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  6.02ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4753373ccdb246b7b246242eca35649e"
          }
        },
        "0036c351554c4006961c8b44805a6158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b5ed87c79a24c0d8d4b31ad708d6a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f7af2510b8a4987af9519d11f0b582e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa745fa819d04d199f75ad7578d80aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7449205bb3b24f2bb7c5b49d35478461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4753373ccdb246b7b246242eca35649e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ae89c11749a4ae7af5d7dd80f0a1ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce226a3b1b914a25b432d8d0240baabb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ba03293bd5fa4d38888947fc764f1d7b",
              "IPY_MODEL_21420de77ce54c169139201b99ceac34",
              "IPY_MODEL_385c5f3be32546c8abe5faa308a4c33c"
            ]
          }
        },
        "ce226a3b1b914a25b432d8d0240baabb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba03293bd5fa4d38888947fc764f1d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a35e1f0e5b3d4348bf96a866b3be5d79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26a6233e6f9246a7be33599fe34f608c"
          }
        },
        "21420de77ce54c169139201b99ceac34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f8d6ee8a0af4f55aa19dcfde12360ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20d9a2a3766a4d07ad746dd560eca686"
          }
        },
        "385c5f3be32546c8abe5faa308a4c33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efe120f19cdf4b23b93ffe1a557f11ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:13&lt;00:00, 34.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f29d04ae86b049328e3f378fa8bdfbd4"
          }
        },
        "a35e1f0e5b3d4348bf96a866b3be5d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26a6233e6f9246a7be33599fe34f608c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f8d6ee8a0af4f55aa19dcfde12360ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20d9a2a3766a4d07ad746dd560eca686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efe120f19cdf4b23b93ffe1a557f11ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f29d04ae86b049328e3f378fa8bdfbd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeleneFabia/nlp-exploration/blob/main/nlp_with_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face NLP Course\n",
        "\n"
      ],
      "metadata": {
        "id": "ggj-itvURGAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "EL72HWG4Rfk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Transformer models"
      ],
      "metadata": {
        "id": "XW9BaK3rdrwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What can Transformers do?\n",
        "\n",
        "Playing around with HuggingFace's OTB models:"
      ],
      "metadata": {
        "id": "la2dcEgcgzkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "CXs80bVxaRsj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"The ocean is beautiful.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Haf-S0XMe5WW",
        "outputId": "3d0b8aa7-0f4a-4c47-9ba0-0863e8b5a906"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998816251754761}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"Looking at the ocean in front of me, I felt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zyK7aVcfOzF",
        "outputId": "bb988a42-89e6-4395-eb3f-3f382f96b69b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Looking at the ocean in front of me, I felt like an airplane flying right.\\n\\nThe storm had descended very quickly, so it appeared this was about to fall at a later date.\\n\\nWe all started feeling a wave of panic:'}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"What is my hobby?\",\n",
        "    context=\"I work as an engineer, but in my free time I enjoy cooking.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17-acrlJfVII",
        "outputId": "d113b7d4-42f2-4bde-a58e-777fd8e4ca06"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'cooking', 'end': 58, 'score': 0.428894579410553, 'start': 51}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do Transformers work?"
      ],
      "metadata": {
        "id": "1olfiIiGg1tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important concepts: \n",
        "- **self-supervised learning**: labels are automatically computed from the input\n",
        "- **pretraining**: training a model from scratch on very large amounts of data\n",
        "- **transfer learning**: fine-tuning a pretrained model in a supervised manner with a smaller dataset for a specific language task\n",
        "- **encoder**: receives input and builds representation of it (optimized for  acquiring an understanding from inputs)\n",
        "- **decoder**: receives encoder's representation plus other inputs in order to generate a target sequence (optimized for generating an output)\n",
        "- **encoder-only models** (e.g., BERT, DistilBERT): for tasks that require understanding of the input e.g., sentence classification, named entity recognition\n",
        "- **decoder-only models** (e.g., GPT, GPT-2): for generative tasks e.g., text generation\n",
        "- **encoder-decoder /seq2seq models** (e.g., BART, Marian): for generative tasks that require an input e.g., translation, summarization\n",
        "- **attention layer**: tells the model to pay attention to specific words in the input\n"
      ],
      "metadata": {
        "id": "qXjSScTphGWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Using HuggingFace Transformers"
      ],
      "metadata": {
        "id": "7ew07kVshL9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple pipeline"
      ],
      "metadata": {
        "id": "Bnn_FifDsSyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer:\n",
        "- splits the input words/subwords/symbols (=tokens), since a model cannot process words directly\n",
        "- maps each token to an integer\n",
        "- adds additional inputs necessary for the model\n",
        "- tokenization needs to happen in exactly the same way as was done with the data used for pretraining a model"
      ],
      "metadata": {
        "id": "vPJDLVTxmcly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "\n",
        "from torch.nn.functional import softmax"
      ],
      "metadata": {
        "id": "4gr-W47rgqZ2"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "Kd3t9LNtnYh9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = [\"I am looking at the ocean. How beautiful!\"]\n",
        "tokenized_input = tokenizer(input, padding=True, truncation=True)\n",
        "print(tokenized_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSJiXRmynjKI",
        "outputId": "24b1c0f8-7ec4-443e-b8e7-f7473fcfb25e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 1045, 2572, 2559, 2012, 1996, 4153, 1012, 2129, 3376, 999, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input[\"input_ids\"] = torch.tensor(tokenized_input[\"input_ids\"])\n",
        "tokenized_input[\"attention_mask\"] = torch.tensor(tokenized_input[\"attention_mask\"])\n",
        "print(tokenized_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUXDuJPAotdr",
        "outputId": "20078822-2f04-4235-82e1-049d1b7fd52c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1045, 2572, 2559, 2012, 1996, 4153, 1012, 2129, 3376,  999,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "input vector:\n",
        "- of shape (batch_size, sequence_length, hidden_size)\n",
        "- batch_size: number of sequences per batch\n",
        "- sequence_length: length of numerical representation of sequence\n",
        "- hidden_size:  vector dimension of each model input (depends on the model)"
      ],
      "metadata": {
        "id": "V8p8kRf1oWSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "U5hIS-vdn0Dx"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(**tokenized_input)\n",
        "print(output.logits)\n",
        "prediction = softmax(output.logits, dim=1)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_XgEvwep2zt",
        "outputId": "02600a3e-56b7-4704-be9a-d4d794ce1492"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.3032,  4.5966]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1.3640e-04, 9.9986e-01]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_id = 0\n",
        "class_prediction = int(torch.argmax(prediction))\n",
        "print(f\"Prediction for sentiment of '{input[input_id]}':\", \n",
        "      model.config.id2label[class_prediction],\n",
        "      f\"with {prediction.tolist()[input_id][class_prediction]:.4f}% probability\"\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVqVEHzBqaZA",
        "outputId": "5f27c33b-5eb3-40c8-a52a-f2534e083c14"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for sentiment of 'I am looking at the ocean. How beautiful!': POSITIVE with 0.9999% probability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "X3cO9btcsWl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import (\n",
        "    BertConfig,\n",
        "    BertModel,\n",
        ")"
      ],
      "metadata": {
        "id": "G9x-xh0VsX5y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig()\n",
        "print(config)\n",
        "model = BertModel(config)  # randomly initialized\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")  # pretrained (https://huggingface.co/bert-base-cased)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUIZfUHMsy_H",
        "outputId": "b332b4db-683d-4dc6-dc92-e97361bc8d9f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.15.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/path/to/my_trained_model\")"
      ],
      "metadata": {
        "id": "f3sT4dr4s25i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizers"
      ],
      "metadata": {
        "id": "OV0-urZ1-R3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used to transform language data into numerical data so that te model can process it. Some approach are:\n",
        "\n",
        "**Word-based tokenizer**\n",
        "- split raw text into words and find numerical representation for them\n",
        "- would need A LOT of different input IDs (one for each word in a language) \n",
        "- no means of showing relationships between words (\"dog\" and \"dogs\" would have different input IDs)\n",
        "- need \"unknown\" token (\"[UNK]\") for words that are not in the vocabulary.\n",
        "\n",
        "**Character-based tokenizer**\n",
        "- raw text is split into characters\n",
        "- fewer distinct input IDs are necessary but numerical sequences would be much longer with this approach\n",
        "\n",
        "**Subword tokenizer**\n",
        "- frequently used words remain as they are, less frequently used ones are split into meaningful subwords (e.g., \"annoyingly\" --> \"annoying\" + \"ly\")\n",
        "- good tradeoff between small number of distinct input IDs and short sequences\n",
        "- examples: WordPiece (BERT), BPE (GPT-2), and Unigram"
      ],
      "metadata": {
        "id": "XK1v2Nv_-a3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    AutoTokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "H2PhghDD-EOE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "# essentially the same, but the second module is a wrapper that can be used with any checkpoint"
      ],
      "metadata": {
        "id": "Rdnmd-6e-Ebk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"The sea is incredibly blue and glittering today.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz1CZNn4-EfE",
        "outputId": "2a49f593-1ece-4e39-e7ea-f6290db9363c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1109, 2343, 1110, 12170, 2221, 1105, 22837, 2052, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**encoding** = general process of converting text to numbers\n",
        "\n",
        "tokenization = splitting text into tokens (according to the way it was done for the pretrained model we want to use)"
      ],
      "metadata": {
        "id": "34r1EEXWAw2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(\"The sea is incredibly blue and glittering today.\")\n",
        "print(tokens)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZBnVsCw-Eic",
        "outputId": "c287046c-e518-4749-94fe-a6d525ec1cd0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'sea', 'is', 'incredibly', 'blue', 'and', 'glittering', 'today', '.']\n",
            "[1109, 2343, 1110, 12170, 2221, 1105, 22837, 2052, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**decoding** = converting numbers to text"
      ],
      "metadata": {
        "id": "CEJaOF7OB4wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.decode(ids)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN6udvxN-Elx",
        "outputId": "3238ce0a-23cc-4e83-b371-f0362d8167a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sea is incredibly blue and glittering today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling multiple sequences"
      ],
      "metadata": {
        "id": "8Roxdcb8CKUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification\n",
        ")"
      ],
      "metadata": {
        "id": "BlnPpCuDCCDD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "_0JM6A4iDFxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = \"Hmmm, I love green tea!\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input = torch.tensor([ids]) # model expects a batch, not one single sample\n",
        "print(input.shape)\n",
        "\n",
        "output = model(input)\n",
        "print(output.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YViKlcN_DZZE",
        "outputId": "a891944e-eeed-478a-e5b6-d12fe8349158"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8])\n",
            "tensor([[-2.6319,  2.8690]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**padding** = making sure all sequences have the same length by adding a padding token"
      ],
      "metadata": {
        "id": "uwrupiBFGF26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\"Hmmm, I love green tea!\", \"It's Thursday\"]  # sequences are of different length!\n",
        "try:\n",
        "  inputs = tokenizer(sequences, return_tensors=\"pt\")\n",
        "  input = inputs[\"input_ids\"]\n",
        "  print(input.shape)\n",
        "  output = model(input)\n",
        "  print(output.logits)\n",
        "except ValueError as error:\n",
        "  print(error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdotW-PyEM1n",
        "outputId": "958b1b98-890e-49b2-c028-bdaca5ab45a6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**attention mask** = tensor of exact same shape as input IDs; filled with 0s and 1s; 1 means a specific token is paid attention to in the attention layer, 0 means it is not paid attention to"
      ],
      "metadata": {
        "id": "UI0VAmFgGX9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [[5, 5, 5], [5, 5, tokenizer.pad_token_id]]\n",
        "attention_mask = [[1, 1, 1], [1, 1, 0]]\n",
        "\n",
        "outputs = model(torch.tensor(input_ids), attention_mask=torch.tensor(attention_mask))\n",
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowPFPudFSQ7",
        "outputId": "d5c42000-2c5b-4843-bce7-af34c9d71bc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8322, -0.7892],\n",
            "        [ 0.3235, -0.2539]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**truncation** = limiting the length of a sequence\n",
        "(necessary because models can only handle up to 512/1024 tokens per sequence - however, there are also models (e.g. Longformer) which can handle longer sequences)"
      ],
      "metadata": {
        "id": "kk-GDVtcHr75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    sequences, \n",
        "    padding=True, \n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"  # or \"np\" for numpy arrays\n",
        "    )"
      ],
      "metadata": {
        "id": "p6p0U2xzIQHN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**special tokens** = added to the inputs, for example [CLS] (= beginning of a sequence) and [SEP] (= end of a sequence)"
      ],
      "metadata": {
        "id": "2OF43e2CIDNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[\"input_ids\"][0])\n",
        "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VoAwmDvIFE4",
        "outputId": "d5709ab3-7730-4832-deed-df85163e5547"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101, 17012,  2213,  1010,  1045,  2293,  2665,  5572,   999,   102])\n",
            "[CLS] hmmm, i love green tea! [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Fine-tuning a pretrained model"
      ],
      "metadata": {
        "id": "YI61NOjTLRzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing the data"
      ],
      "metadata": {
        "id": "ugOIBcAAMRj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding"
      ],
      "metadata": {
        "id": "ODTrxt7dJxVi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"glue\", \"mrpc\", split=\"train\")\n",
        "print(\"Columns:\", ds.column_names)\n",
        "print(\"Number of samples:\", len(ds))\n",
        "print(\"Classes:\", ds.features[\"label\"].names)\n",
        "print(\"Example:\", ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frnugPTwMzoP",
        "outputId": "98051ec2-912d-40ce-feb1-733c5d344e0e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['sentence1', 'sentence2', 'label', 'idx']\n",
            "Number of samples: 3668\n",
            "Classes: ['not_equivalent', 'equivalent']\n",
            "Example: {'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "1LxFinwsNIPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**token type ids** = in this example, the tensor tells the model which input ids belong to the first sentence and which belong to the second sentence."
      ],
      "metadata": {
        "id": "S8v-5NGcOs5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(ds[\"sentence1\"][10], ds[\"sentence2\"][10])\n",
        "print(inputs[\"input_ids\"])\n",
        "print(inputs[\"token_type_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIyWymhdNuwv",
        "outputId": "f7294724-eda9-40c4-979d-21ee36301f20"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 6094, 2437, 2009, 6211, 2005, 10390, 2000, 22505, 2037, 13930, 1999, 10528, 2457, 2180, 10827, 2160, 6226, 1999, 2233, 1012, 102, 6094, 2437, 2009, 6211, 2005, 10390, 2000, 22505, 2037, 13930, 1999, 10528, 2457, 2180, 26203, 1010, 2160, 6226, 1999, 2233, 1998, 2001, 11763, 2011, 1996, 2317, 2160, 1012, 102]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds = tokenizer(\n",
        "    ds[\"sentence1\"],\n",
        "    ds[\"sentence1\"],\n",
        "    padding=True,\n",
        "    truncation=True\n",
        ")  # will require a lot of RAM; will return the dataset as a dictionary"
      ],
      "metadata": {
        "id": "2amlDhHDOj0T"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_func(dataset):  # use with Dataset.map() method\n",
        "  return tokenizer(dataset[\"sentence1\"], dataset[\"sentence2\"], truncation=True)\n",
        "  # no padding, since whole dataset would be padded to the same length (unnecessary)\n",
        "  # instead, padding is applied to each batch "
      ],
      "metadata": {
        "id": "OzS6EF2nPqt0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"glue\", \"mrpc\")\n",
        "print(ds)\n",
        "tokenized_ds = ds.map(tokenize_func, batched=True)\n",
        "print(tokenized_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658,
          "referenced_widgets": [
            "c2366d78eee34564b5ddb81ef1e3f9df",
            "944c636a4ed74bd594ee590b9f4d9767",
            "aadee3faa2324a398330421f3c791d6b",
            "772c71e15ed843a3a2c128f4a6a4f993",
            "f2472e3fb5d748849bba736d1e878cbc",
            "bdf4970dd87247b1a38f4f14b2bef2cf",
            "76f756b9d3ea4afbb40ce402ea0aa2f5",
            "9a458e0e8a5a4f259e51ad62697f02ce",
            "1815442e0ea54d3f82ff5dca53d76ac1",
            "c65dc5ac07f74ec68e1aa64a3d067764",
            "59f30938374944f1a5f2a258c59d9412",
            "86638f4637694954ba4c47ea7fa657c0",
            "2e6b1274a82045f29b3b03488dc5a250",
            "67d05f6270734c13b91af073076faf47",
            "28b47bb248c94c2384fa4fbded5882ec",
            "6d205bf89cbc4f3fa6afdfe4dcd006c6",
            "00b754ceec9a409198adc96e5df4b201",
            "c80ac0e8f1384342a0e9fa6000a1ca16",
            "e43e199ba94f415ca2f774590c405c20",
            "914ce147edbe4c308b0ffa2dd35ed851",
            "cff1bb1518e544ed932264857c4f6903",
            "667144992b8d45b8918a6ae220725561",
            "a8a96cb943de4cf39f2b6a9876e55141",
            "253f3722292247488e5eacc1efe8ad46",
            "b08ef877b51f420492d7b3569e72d31b",
            "049c2becd460423583087dfaebbd4e9d",
            "4bb229c9625348f6b98b140b84efa1e0",
            "f86476e1c4a74f17a7cc80d86668a647",
            "2cd763587be54a868c1947730d82ee32",
            "d155ba5846b74184ad81cf7a591203dc",
            "3e56cb107bf34af1a60393f4dbd81257",
            "22829a9cd4f84f34b87281df5c66bb2a",
            "dd96b11555b84777a397675495f90871",
            "4d329ec16e174052ae7b2ae195055c77",
            "b9eb064e07a14575913afea9774cf43b",
            "d6bb7aac74ea482dbd6de7a019f63a0a",
            "ba696fc8349644b8ba72a4dd28ef531b",
            "b88a56c26db54ba6beebaf7017478b02",
            "0036c351554c4006961c8b44805a6158",
            "0b5ed87c79a24c0d8d4b31ad708d6a82",
            "0f7af2510b8a4987af9519d11f0b582e",
            "fa745fa819d04d199f75ad7578d80aea",
            "7449205bb3b24f2bb7c5b49d35478461",
            "4753373ccdb246b7b246242eca35649e"
          ]
        },
        "id": "TD0iDTR6PrA9",
        "outputId": "ff02576b-ca10-4ff3-c2ee-d0988fcea56d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2366d78eee34564b5ddb81ef1e3f9df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 3668\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 408\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
            "        num_rows: 1725\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86638f4637694954ba4c47ea7fa657c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8a96cb943de4cf39f2b6a9876e55141",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d329ec16e174052ae7b2ae195055c77",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],\n",
            "        num_rows: 3668\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],\n",
            "        num_rows: 408\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],\n",
            "        num_rows: 1725\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**dynamic padding** = apply padding in the collate function that builds the DataLoader"
      ],
      "metadata": {
        "id": "zdyjKzBsRseV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "_tU8K1JnQp4A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = tokenized_ds[\"train\"][:6]\n",
        "print([len(sample) for sample in samples[\"input_ids\"]]) # sequences are still of different lengths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI5jxQF3R681",
        "outputId": "31fdec28-db40-4934-f05a-741edf0cb85d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50, 59, 47, 67, 59, 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
        "batch = data_collator(samples)  # automatically padded to max length in whole dataset\n",
        "print({k: v.shape for k, v in batch.items()})  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMG5sHYwR6_7",
        "outputId": "23cf022f-4bde-45d8-9d17-851627f29078"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': torch.Size([6, 67]), 'input_ids': torch.Size([6, 67]), 'token_type_ids': torch.Size([6, 67]), 'labels': torch.Size([6])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning a model with the Trainer API"
      ],
      "metadata": {
        "id": "igR6lRrzTnLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from transformers import (\n",
        "    TrainingArguments,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer\n",
        "    )\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "1RIRVNLNUCC1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")"
      ],
      "metadata": {
        "id": "nCoVoxIgUHqm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "8ae89c11749a4ae7af5d7dd80f0a1ed8",
            "ce226a3b1b914a25b432d8d0240baabb",
            "ba03293bd5fa4d38888947fc764f1d7b",
            "21420de77ce54c169139201b99ceac34",
            "385c5f3be32546c8abe5faa308a4c33c",
            "a35e1f0e5b3d4348bf96a866b3be5d79",
            "26a6233e6f9246a7be33599fe34f608c",
            "0f8d6ee8a0af4f55aa19dcfde12360ab",
            "20d9a2a3766a4d07ad746dd560eca686",
            "efe120f19cdf4b23b93ffe1a557f11ba",
            "f29d04ae86b049328e3f378fa8bdfbd4"
          ]
        },
        "id": "lGK3N3rjW8Nd",
        "outputId": "e57d234a-5d46-411d-c060-ca2f7d255e36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ae89c11749a4ae7af5d7dd80f0a1ed8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(valid_preds):\n",
        "  metric = load_metric(\"glue\", \"mrpc\"),\n",
        "  logits, labels = valid_preds\n",
        "  preds_cls = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=preds_cls, references=labels)"
      ],
      "metadata": {
        "id": "Rfe_l8OuY_1Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "SDo-aL4qW8di"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "nxn_GahEWsHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A full training"
      ],
      "metadata": {
        "id": "8aceUinXZte1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AdamW,\n",
        "    get_scheduler\n",
        ")\n",
        "from datasets import load_metric\n",
        "# from accelerate import Accelerator"
      ],
      "metadata": {
        "id": "ryoUw93sU-rn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds = tokenized_ds.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
        "tokenized_ds.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "YZNpDcpUZugU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(\n",
        "    tokenized_ds[\"train\"], \n",
        "    shuffle=True, \n",
        "    batch_size=8,\n",
        "    collate_fn=data_collator\n",
        "    )\n",
        "\n",
        "valid_dl = DataLoader(\n",
        "    tokenized_ds[\"validation\"], \n",
        "    batch_size=8, \n",
        "    collate_fn=data_collator\n",
        "    )"
      ],
      "metadata": {
        "id": "szBUPwdtU9HN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dl:  # padding is applied to max length of respective batch\n",
        "  print({k: v.shape for k, v in batch.items()})\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U09jPUQkVXji",
        "outputId": "dec6b611-db3b-465f-f0f0-f4bc206e129a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': torch.Size([8, 72]), 'input_ids': torch.Size([8, 72]), 'labels': torch.Size([8]), 'token_type_ids': torch.Size([8, 72])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "lESM-2gRVpIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "BLXvuV8aWKZ6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accelerator = Accelerator()"
      ],
      "metadata": {
        "id": "q8nZZAljZfkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dl)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "sSo74MQLWxun"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# train_dl, valid_dl, model, optimizer = accelerator.prepare(\n",
        "#    train_dl, \n",
        "#    valid_dl,\n",
        "#    model,\n",
        "#    optimizer\n",
        "#)  # --> handles device placement so putting model and data on device during training is unnecessary when working with Accelerator"
      ],
      "metadata": {
        "id": "b6KbMVcsXAIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(range(num_training_steps))\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for batch in train_dl:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "  \n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    # accelerator.backward(loss)\n",
        "    \n",
        "    optimizer.step()\n",
        "    lr_scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    progress_bar.update(1)"
      ],
      "metadata": {
        "id": "4ly_e_-oXUD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"glue\", \"mrpc\")\n",
        "model.eval()\n",
        "for batch in valid_dl:\n",
        "  batch = {k: v.to(device) for k, v in batch.items()}\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**batch)\n",
        "  logits = outputs.logits\n",
        "  predictions = torch.argmax(logits, dim=-1)\n",
        "  metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "metric.compute()"
      ],
      "metadata": {
        "id": "lsXCBYjdYCBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Datasets library"
      ],
      "metadata": {
        "id": "D8nETDBoRMLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import (\n",
        "    load_dataset_builder, \n",
        "    load_dataset,\n",
        ")\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    AutoTokenizer\n",
        ")\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import(\n",
        "    DataLoader\n",
        ")"
      ],
      "metadata": {
        "id": "6lVynTbIRDi5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_builder = load_dataset_builder(path=\"poem_sentiment\")\n",
        "\n",
        "train_dataset = load_dataset(path=\"poem_sentiment\", split=\"train\")\n",
        "# valid_dataset = load_dataset(path=\"poem_sentiment\", split=\"validation\")\n",
        "# test_dataset = load_dataset(path=\"poem_sentiment\", split=\"test\")"
      ],
      "metadata": {
        "id": "q1_6R2RdRabm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Description:\", train_dataset.description)\n",
        "print(\"Num data entries:\", len(train_dataset))\n",
        "print(\"Column names:\", train_dataset.column_names)\n",
        "print(\"Classes:\", train_dataset.features[\"label\"].names)\n",
        "print(\"Example data entry:\", train_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYEbNPw0ThoP",
        "outputId": "ceb3e084-91ef-488b-e0c6-3e13b6670f76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description: Poem Sentiment is a sentiment dataset of poem verses from Project Gutenberg. This dataset can be used for tasks such as sentiment classification or style transfer for poems.\n",
            "\n",
            "Num data entries: 892\n",
            "Column names: ['id', 'verse_text', 'label']\n",
            "Classes: ['negative', 'positive', 'no_impact', 'mixed']\n",
            "Example data entry: {'id': 0, 'verse_text': 'with pale blue berries. in these peaceful shades--', 'label': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "bKBHTgjCUS6X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_enc_ds = train_dataset.map(lambda examples: \n",
        "                                          tokenizer(\n",
        "                                              examples[\"verse_text\"], \n",
        "                                              truncation=True,\n",
        "                                              padding=\"max_length\",\n",
        "                                          ),\n",
        "                                 batched=True\n",
        "                                 )"
      ],
      "metadata": {
        "id": "C_szpKZAVZws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column names of encoded dataset:\", train_enc_ds.column_names)\n",
        "print(\"Tokenized data entry:\", train_enc_ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfoaHcQJXmUi",
        "outputId": "53f4e7a5-bfd8-4111-aa3d-2e58e135195b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names of encoded dataset: ['attention_mask', 'id', 'input_ids', 'label', 'token_type_ids', 'verse_text']\n",
            "Tokenized data entry: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'id': 0, 'input_ids': [101, 1114, 4554, 2221, 26571, 119, 1107, 1292, 9441, 16327, 118, 118, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'verse_text': 'with pale blue berries. in these peaceful shades--'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use dataset with pytorch\n",
        "train_enc_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# create pytorch data loader\n",
        "train_dl = DataLoader(train_enc_ds, batch_size=32)\n",
        "next(iter(train_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2qNF-9iZmYy",
        "outputId": "aa26e791-b87f-42d0-8cfb-2b77679b5f0b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'input_ids': tensor([[  101,  1114,  4554,  ...,     0,     0,     0],\n",
              "         [  101,  1122,  5611,  ...,     0,     0,     0],\n",
              "         [  101,  1105,  1115,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  1106,  1115,  ...,     0,     0,     0],\n",
              "         [  101,   192,  2386,  ...,     0,     0,     0],\n",
              "         [  101,  1123, 15219,  ...,     0,     0,     0]]),\n",
              " 'label': tensor([1, 2, 0, 3, 3, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Tokenizers library"
      ],
      "metadata": {
        "id": "z-a0M-C9bcwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When training a model from scratch, it also makes sense to train the tokenizer from scratch. (Training a model from scratch makes sense if a model is not available in a particular language or if your corpus is very different from those other models were trained on). So whenever you want to pretrain a model and the dataset is different from the on used by an existing pretraiend model, you have to train a new tokenizer."
      ],
      "metadata": {
        "id": "RGJTWieacTyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training a new tokenizer from an old one"
      ],
      "metadata": {
        "id": "GUd0ekDEceeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tokenizer needs to be trained on a corpus in order to identify subwords that are of interest and occur most frequently in the corpus. Training a tokenizer is unlike training a model - it's a statistical process with the exact rules depending on the tokenization algorithm. It's not random (like model) but deterministic."
      ],
      "metadata": {
        "id": "jfpxfNMpc8VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "mJP_o_Z4bcFP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_ds = load_dataset(\"code_search_net\", \"python\")"
      ],
      "metadata": {
        "id": "jrUVMzDpdyxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_ds[\"train\"])\n",
        "print(raw_ds[\"train\"][1][\"whole_func_string\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvErSNFgd2XN",
        "outputId": "5e81937d-c2d7-44bc-eb88-18a382a15c05"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
            "    num_rows: 412178\n",
            "})\n",
            "def close(self):\n",
            "        '''\n",
            "        Cleanly shutdown the router socket\n",
            "        '''\n",
            "        if self._closing:\n",
            "            return\n",
            "        log.info('MWorkerQueue under PID %s is closing', os.getpid())\n",
            "        self._closing = True\n",
            "        # pylint: disable=E0203\n",
            "        if getattr(self, '_monitor', None) is not None:\n",
            "            self._monitor.stop()\n",
            "            self._monitor = None\n",
            "        if getattr(self, '_w_monitor', None) is not None:\n",
            "            self._w_monitor.stop()\n",
            "            self._w_monitor = None\n",
            "        if hasattr(self, 'clients') and self.clients.closed is False:\n",
            "            self.clients.close()\n",
            "        if hasattr(self, 'workers') and self.workers.closed is False:\n",
            "            self.workers.close()\n",
            "        if hasattr(self, 'stream'):\n",
            "            self.stream.close()\n",
            "        if hasattr(self, '_socket') and self._socket.closed is False:\n",
            "            self._socket.close()\n",
            "        if hasattr(self, 'context') and self.context.closed is False:\n",
            "            self.context.term()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It makes sense converting the dataset to an iterator (e.g., a list of lists of texts), so that the tokenizer can train on batches of texts AND the whole dataset does not need to be loaded into memory all at once."
      ],
      "metadata": {
        "id": "niJzdD6sekZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training_corpus = [\n",
        "#                   raw_ds[\"train\"][i: i + 1000][\"whole_func_string\"] \n",
        "#                   for i in range(0, len(raw_ds[\"train\"]), 1000)\n",
        "#                   ]\n",
        "# creates a list of lists of 1000 texts each and load it into memory\n",
        "\n",
        "# use parentheses instead of brackets to create a Python generator that does not\n",
        "# load anything into memory until it's necessary.\n",
        "# nothing is loaded into memory but object is created that can be used in Python\n",
        "# for loop - however, the object can only be used once\n",
        "\n",
        "training_corpus = (\n",
        "    raw_ds[\"train\"][i: i + 1000][\"whole_func_string\"] \n",
        "    for i in range(0, len(raw_ds[\"train\"]), 1000)\n",
        ")"
      ],
      "metadata": {
        "id": "U-n5lCyIeTed"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen1 = (i for i in range(10))\n",
        "gen2 = [i for i in range(10)]\n",
        "print(gen1)\n",
        "print(gen2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvPQ_SBzf_kt",
        "outputId": "44cf973b-af34-49ea-d410-ae7bb70ac0c6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object <genexpr> at 0x7f8cf2e11b50>\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus():\n",
        "  return (\n",
        "      raw_ds[\"train\"][i: i + 1000][\"whole_func_string\"]\n",
        "      for i in range(0, len(raw_ds[\"train\"]), 1000)\n",
        "  )\n",
        "\n",
        "# ALTERNATIVE: use yield statement to create generator\n",
        "# def get_training_corpus():\n",
        "#  for start_idx in range(0, len(raw_ds[\"train\"]), 1000):\n",
        "#    yield raw_ds[\"train\"][start_idx: start_idx + 1000][\"whole_func_string\"] \n",
        "\n",
        "training_corpus = get_training_corpus()"
      ],
      "metadata": {
        "id": "FBr2lOekgSep"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "# not starting *entirely* from scratch but using tokenization algorithm of GPT-2"
      ],
      "metadata": {
        "id": "3P0400jJhEbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = '''def add_numbers(a, b):\n",
        "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
        "    return a + b'''\n",
        "\n",
        "print(old_tokenizer.tokenize(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhgpSlrzh2q7",
        "outputId": "7f0cb140-c491-42a2-bd23-ccc26766565d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['def', 'Ġadd', '_', 'n', 'umbers', '(', 'a', ',', 'Ġb', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ\"\"\"', 'Add', 'Ġthe', 'Ġtwo', 'Ġnumbers', 'Ġ`', 'a', '`', 'Ġand', 'Ġ`', 'b', '`', '.\"', '\"\"', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, vocab_size=52000)"
      ],
      "metadata": {
        "id": "UUcuKWIpiNgr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.tokenize(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxu1FWWyihYO",
        "outputId": "c3fa25a7-6ae1-4e8f-e7cd-ed1ef2bb1faa"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['def', 'Ġadd', '_', 'numbers', '(', 'a', ',', 'Ġb', '):', 'ĊĠĠĠ', 'Ġ\"\"\"', 'Add', 'Ġthe', 'Ġtwo', 'Ġnumbers', 'Ġ`', 'a', '`', 'Ġand', 'Ġ`', 'b', '`.\"\"\"', 'ĊĠĠĠ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization and pre-tokenization"
      ],
      "metadata": {
        "id": "zgoXeuB_n2A2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before splitting a text into subtokens, a tokenizer performs normalization and pre-tokenization before.\n",
        "\n",
        "**normalization** = general cleaning e.g., removing unnecessary whitespaces, lowercasing, removing accents"
      ],
      "metadata": {
        "id": "Q_lP-_LHoB3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "VKqwdfgikES2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "Bw6PJ1cgoWWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.backend_tokenizer.normalizer.normalize_str(\"Hellö, how ARE YOU tòday?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYoNhxphoinn",
        "outputId": "69b4f1e6-f269-44e4-ccbe-937b00762405"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello, how are you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pre-tokenization** = splitting the text into smaller entities i.e., words (e.g., at whitespaces or punctuation) (which are later split into tokens)."
      ],
      "metadata": {
        "id": "3YxeoKe9pW2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\"hello, how are you today?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGx-_MW6o74h",
        "outputId": "471073e6-d53a-40e4-d2ca-19be106fbc23"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', (0, 5)), (',', (5, 6)), ('how', (7, 10)), ('are', (11, 14)), ('you', (15, 18)), ('today', (19, 24)), ('?', (24, 25))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Byte-Pair Encoding (BPE) tokenization"
      ],
      "metadata": {
        "id": "LmHV_SVrp9-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- used for training GPT models\n",
        "\n",
        "Training of tokenizer:\n",
        "- first, normalization and pre-tokenization are applied\n",
        "- computes unique set of words and builds vocabulary by taking all the symbols used to write those words\n",
        "  - corpus: `[\"hug\", \"pug\", \"pun\", \"bun\", \"hugs\"]`\n",
        "  - initial vocabulary: `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]` \n",
        "- vocabulary is expanded by learning merges i.e., merging two elements of existing vocabulary - as such, longer and longer subwords are added to the vocabulary\n",
        "  - this is done by looking by the most frequent \"pair\" i.e., the most frequently appearing merge between elements in the existing vocabulary. The most frequent pair will be merged and added to the vocabulary. Then the processed is repeated.\n",
        "  - vocabulary during merging: `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\"]` --> `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\"]` --> `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]` --> ...\n",
        "\n",
        "Tokenization with trained tokenizer:\n",
        "- normalization\n",
        "- pre-tokenization\n",
        "- splitting words into individual characters\n",
        "- applying merge rules learned in order to those splits\n",
        "- example: `\"unhug\"` will be tokenized as `[\"un\", \"hug\"]`, `\"bug\"` as `[\"[UNK]\", \"ug\"]` (since \"b\" was not in the corpus with which tokenizer was trained)"
      ],
      "metadata": {
        "id": "HEb2WBXPq5Yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WordPiece tokenization"
      ],
      "metadata": {
        "id": "E8XZ1qogiy8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- starts like BPE from base vocabulary and then learns merging rules\n",
        "- does not select most frequent pairs (like BPE) but calculates special score for each pair\n",
        "- does not save the rules learned from training (like BPE) but saves only the final vocabulary"
      ],
      "metadata": {
        "id": "9N_lycAgi2g1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unigram tokenization"
      ],
      "metadata": {
        "id": "Vjq2PFevjfNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- starts from a big vocabulary and removes tokens from it until it reaches a desired vocabulary size\n",
        "computes loss over the corpus given the current vocabulary and iterativels removes the 10-20% of tokens based on how little the loss would increase by their removal\n",
        "\n"
      ],
      "metadata": {
        "id": "968REWbvji7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a tokenizer, block by block"
      ],
      "metadata": {
        "id": "BWPnqZxLkjYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization consists of \n",
        "- normalization\n",
        "- pre-tokenization\n",
        "- tokenizer model (like BPE, WordPiece, ...)\n",
        "- post-processing (adding special tokens, generating attention mask and token type IDs)"
      ],
      "metadata": {
        "id": "ygEYdRDTkxLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from tokenizers import (\n",
        "    decoders,\n",
        "    models,\n",
        "    normalizers,\n",
        "    pre_tokenizers,\n",
        "    processors,\n",
        "    trainers,\n",
        "    Tokenizer\n",
        ")\n",
        "from transformers import (\n",
        "    PreTrainedTokenizerFast,\n",
        "    BertTokenizerFast\n",
        ")"
      ],
      "metadata": {
        "id": "WrI02LMCkoo1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"wikitext\", name=\"wikitext-2-raw-v1\", split=\"train\")"
      ],
      "metadata": {
        "id": "U5vO4PVBqX-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus():\n",
        "  for i in range(0, len(ds), 1000):\n",
        "    yield ds[i: i + 1000][\"text\"]"
      ],
      "metadata": {
        "id": "hyTNX8zCqgpe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model block\n",
        "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))"
      ],
      "metadata": {
        "id": "FuoWC5uaseKQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizer block \n",
        "tokenizer.normalizer = normalizers.Sequence(\n",
        "    [\n",
        "     normalizers.NFD(),  # NFD Unicode normalizer\n",
        "     normalizers.Lowercase(),\n",
        "     normalizers.StripAccents()\n",
        "    ]\n",
        ")\n",
        "print(tokenizer.normalizer.normalize_str(\"Héllò hôw are ü?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFUlMEs4sjKk",
        "outputId": "5ccd85f5-73bd-4c99-bd6f-ed23713c7cc0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello how are u?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-tokenizer block\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace() # splits of whitespaces and punctuation (excluding underscore character)\n",
        "print(tokenizer.pre_tokenizer.pre_tokenize_str(\"Today's such a beautiful and sunny day.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FPSlIzPtLXM",
        "outputId": "07dff018-b2e9-4c8c-c8d3-758c97610add"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Today', (0, 5)), (\"'\", (5, 6)), ('s', (6, 7)), ('such', (8, 12)), ('a', (13, 14)), ('beautiful', (15, 24)), ('and', (25, 28)), ('sunny', (29, 34)), ('day', (35, 38)), ('.', (38, 39))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train tokenizer\n",
        "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)\n",
        "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
      ],
      "metadata": {
        "id": "Y-jJfk6Hts2Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer.encode(\"Let's test the tokenizer, shall we?\")\n",
        "print(\"Tokens:\", encoding.tokens)\n",
        "print(\"Input IDs:\", encoding.ids)\n",
        "print(\"Offsets:\", encoding.offsets)\n",
        "print(\"Attention mask:\", encoding.attention_mask)\n",
        "print(\"Special token mask:\", encoding.special_tokens_mask)\n",
        "print(\"Overflowing:\", encoding.overflowing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ati3a0duKqq",
        "outputId": "6b6c6087-3e5f-4754-c3b9-a2791bc7da9e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['let', \"'\", 's', 'test', 'the', 'tok', '##eni', '##zer', ',', 'shall', 'we', '?']\n",
            "Input IDs: [3019, 11, 61, 3611, 1333, 24319, 18903, 6614, 16, 11448, 1626, 35]\n",
            "Offsets: [(0, 3), (3, 4), (4, 5), (6, 10), (11, 14), (15, 18), (18, 21), (21, 24), (24, 25), (26, 31), (32, 34), (34, 35)]\n",
            "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Special token mask: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Overflowing: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# post-processing\n",
        "cls_token_id = tokenizer.token_to_id(\"[CLS]\") # to add at beginning of sequence\n",
        "sep_token_id = tokenizer.token_to_id(\"[SEP]\") # to add at end of each sentence in sequence\n",
        "print(\"[CLS]\", cls_token_id, \"[SEP]\", sep_token_id)\n",
        "\n",
        "tokenizer.post_processor = processors.TemplateProcessing(\n",
        "    single=\"[CLS]:0 $A:0 [SEP]:0\", # token type IDs for single sentences ($A means single sentence)\n",
        "    pair=\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\", # tokent type IDs to use for sentence pairs ($B)\n",
        "    special_tokens=[(\"[CLS]\", cls_token_id), (\"[SEP]\", sep_token_id)]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztN3IveHupZ-",
        "outputId": "8b7b7a0e-f0c9-48d1-c398-6362b2ee884e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 2 [SEP] 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer.encode(\"Let's test the tokenizer, shall we?\")\n",
        "print(\"Tokens:\", encoding.tokens)\n",
        "print(\"Input IDs:\", encoding.ids)\n",
        "print(\"Offsets:\", encoding.offsets)\n",
        "print(\"Attention mask:\", encoding.attention_mask)\n",
        "print(\"Special token mask:\", encoding.special_tokens_mask)\n",
        "print(\"Overflowing:\", encoding.overflowing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsYX7Dddvizu",
        "outputId": "9611ae75-43ab-4009-865a-323180b08c96"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['[CLS]', 'let', \"'\", 's', 'test', 'the', 'tok', '##eni', '##zer', ',', 'shall', 'we', '?', '[SEP]']\n",
            "Input IDs: [2, 3019, 11, 61, 3611, 1333, 24319, 18903, 6614, 16, 11448, 1626, 35, 3]\n",
            "Offsets: [(0, 0), (0, 3), (3, 4), (4, 5), (6, 10), (11, 14), (15, 18), (18, 21), (21, 24), (24, 25), (26, 31), (32, 34), (34, 35), (0, 0)]\n",
            "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Special token mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "Overflowing: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder\n",
        "tokenizer.decoder = decoders.WordPiece(prefix=\"##\")\n",
        "\n",
        "tokenizer.decode(encoding.ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "r8sAmVB3wyvx",
        "outputId": "7eadf2df-a7a9-4d82-bcfe-4759938d7482"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"let's test the tokenizer, shall we?\""
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save tokenizer\n",
        "tokenizer.save(\"tokenizer.json\")\n",
        "\n",
        "#load tokenizer\n",
        "new_tokenizer = Tokenizer.from_file(\"tokenizer.json\")"
      ],
      "metadata": {
        "id": "A_v83ZDZxQa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap tokenizer in PreTrainedTokenizerFast\n",
        "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_object=tokenizer,\n",
        "    # tokenizer_file=\"tokenizer.json\",  # alternatively, load from file \n",
        "    unk_token=\"[UNK]\",\n",
        "    pad_token=\"[PAD]\",\n",
        "    cls_token=\"[CLS]\",\n",
        "    sep_token=\"[SEP]\",\n",
        "    mask_token=\"[MASK]\"\n",
        ")"
      ],
      "metadata": {
        "id": "BJqTbbhKxcV9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a BPE (GPT-2) tokenizer from scratch:"
      ],
      "metadata": {
        "id": "gRVo5fI-y6R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose model\n",
        "tokenizer = Tokenizer(models.BPE())"
      ],
      "metadata": {
        "id": "Um1EU0yfy16l"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add pre-tokenizer (not normalizer needed for GPT-2 tokenizer)\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False) # add_prefix_space add space at beginning of sentence"
      ],
      "metadata": {
        "id": "t58tA0vjy_gM"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train tokenizer\n",
        "trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=[\"<|endoftext|>\"])\n",
        "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
      ],
      "metadata": {
        "id": "O5AjMiDezjr-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# post-processing\n",
        "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False) # trim_offset means that start of offset will point at first character of word, not at space before it\n"
      ],
      "metadata": {
        "id": "PPVJakumz5UT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder\n",
        "tokenizer.decoder = decoders.ByteLevel()"
      ],
      "metadata": {
        "id": "gVrEuUAW0hSJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_object=tokenizer,\n",
        "    bos_token=\"<|endoftext|>\",\n",
        "    eos_token=\"<|endoftext|>\"\n",
        ")\n",
        "# OR\n",
        "# wrapped_tokenizer = GPT2TokenizerFast(tokenier_object=tokenizer)"
      ],
      "metadata": {
        "id": "r7jXofmR0m52"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Main NLP tasks"
      ],
      "metadata": {
        "id": "M1nxM2Hf2daM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token classification\n",
        "\n",
        "- **Named entity recognition (NER)**: find names, locations and organization in a sentence; assign class to each token\n",
        "- **Part-of-speech tagging (POS)**: mark each word as its respective par of speech (e.g., noun, verb,...)\n",
        "- **Chunking**: find tokens that belong to the same entity"
      ],
      "metadata": {
        "id": "XXGQZvCq30ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning a masked language model\n",
        "\n",
        "- pre-trained model can be fine-tuned on your data if the dataset is not too different from the corpus used from pretraining the model\n",
        "- **domain adaptation**: on example of fine-tuning a model, namely on a dataset of special domain texts"
      ],
      "metadata": {
        "id": "eXQi92am52Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForMaskedLM,\n",
        "    AutoTokenizer\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import torch"
      ],
      "metadata": {
        "id": "vfn6juwu5hMC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased\"\n",
        "model = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "YcOTQhBX6o-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a great [MASK].\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "token_logits = model(**inputs).logits\n",
        "mask_token_idx = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "mask_token_logits = token_logits[0, mask_token_idx, :]\n",
        "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
        "\n",
        "for token in top_5_tokens:\n",
        "  print(f\"{text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNYj2YxxAX2d",
        "outputId": "750d4740-9695-4ce9-93fe-eadf86f0112c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a great deal.\n",
            "This is a great success.\n",
            "This is a great adventure.\n",
            "This is a great idea.\n",
            "This is a great feat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_ds = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "T-bJ9WX6Bb1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_ds[\"train\"][\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pguggYPVC1i1",
        "outputId": "7de59afd-7d71-420e-fd5f-22e27dfd7c37"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_8hSF93sDDFk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}